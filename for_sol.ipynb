{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proccesing embedding CSV files:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when creating the percentile data, you need to choose the desired percentiles values (results 1-3 below) and the Similarity metrix used in faiss (Cosine or Euclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"./embeddings/cvcs/\"\n",
    "# json file names and their threshold list:\n",
    "# results 1(just resulst as filename):[25, 50, 75, 90, 95, 99]\n",
    "# results 2: [10, 25, 40, 50, 60, 75, 90, 95]\n",
    "# results 3: [5, 15, 25, 35, 50, 70, 80, 90, 95]\n",
    "PERCENTILES = [5, 15, 25, 35, 50, 70, 80, 90, 95] ## does not matter in creating netx graphs function\n",
    "# cosine, euclidean (=l2)\n",
    "METRIC = \"cosine\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function below runs on embedding CSV file of each of the patients, and creates the percentiles vector according to different k values, that leads to different adjacency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_percentiles(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    # Extract TCR sequences and embeddings\n",
    "    tcr_sequences = df.iloc[:, 0].values\n",
    "    embeddings = df.iloc[:, 1:].values.astype('float32')\n",
    "\n",
    "    # Function to create FAISS index and search for nearest neighbors\n",
    "    def create_faiss_index(embeddings, k, distance_metric = 'cosine'):\n",
    "        if distance_metric == 'cosine':\n",
    "            # Normalize the embeddings\n",
    "            embeddings = embeddings / np.linalg.norm(embeddings, axis=1)[:, np.newaxis]\n",
    "            # When embeddings are normalized, the inner product is equivalent to cosine similarity. \n",
    "            index = faiss.IndexFlatIP(embeddings.shape[1])  # Using inner product(IP) for cosine similarity\n",
    "        elif distance_metric == 'euclidean':\n",
    "            # should not normelize beforeahand, or it will distort their original magnitudes\n",
    "            index = faiss.IndexFlatL2(embeddings.shape[1])  # Using L2 distance (Euclidean)\n",
    "        index.add(embeddings)\n",
    "        distances, indices = index.search(embeddings, k)\n",
    "        return distances, indices\n",
    "\n",
    "    # Function to create the adjacency matrix\n",
    "    def create_adjacency_matrix(num_embeddings, indices, distances, k):\n",
    "        adjacency_matrix = np.zeros((num_embeddings, num_embeddings))\n",
    "        for i in range(num_embeddings):\n",
    "            for j in range(1, k):  # Skip the first neighbor (itself)\n",
    "                adjacency_matrix[i, indices[i, j]] = distances[i, j]\n",
    "        return adjacency_matrix\n",
    "\n",
    "    # Define different k values to explore\n",
    "    N = embeddings.shape[0]\n",
    "    log_k = int(np.log(N))\n",
    "    if log_k == 0:\n",
    "        log_k += 1\n",
    "    k_values = [5, 10, 15, 20, int(np.sqrt(N)), int((np.sqrt(N))/2)]\n",
    "    # Ensure log_k is unique\n",
    "    if log_k in k_values:\n",
    "        log_k += 1\n",
    "    # Add log_k to k_values\n",
    "    k_values.append(log_k)\n",
    "\n",
    "    percentiles = PERCENTILES # Standard percentiles to calculate\n",
    "    percentiles_dict = {}  # Dictionary to store percentiles\n",
    "\n",
    "    for k in k_values:\n",
    "        distances, indices = create_faiss_index(embeddings, k, distance_metric=METRIC)\n",
    "        adjacency_matrix = create_adjacency_matrix(embeddings.shape[0], indices, distances, k)\n",
    "        \n",
    "        distances_flat = adjacency_matrix.flatten()\n",
    "        distances_flat = distances_flat[distances_flat > 0]\n",
    "        calculated_percentiles = np.percentile(distances_flat, percentiles)\n",
    "        percentiles_dict[k] = calculated_percentiles\n",
    "\n",
    "    return percentiles_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running ML on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare data function is responsible for loading the percentiles data (in jsong file. each patient has a vector of K nearest neightbor values, and each k value has a percentiles vector).\n",
    "after loading the data, it is converted to numpy format and splited into train and test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "\n",
    "def prepare_data(percentiles_data, labels_dict, vector_indices=None, average_vectors=False):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    if average_vectors:\n",
    "        for sample_name, percentiles_dict in percentiles_data.items():\n",
    "            vectors = np.array(list(percentiles_dict.values()))\n",
    "            avg_vector = np.mean(vectors, axis=0)\n",
    "            data.append(avg_vector)\n",
    "            labels.append(labels_dict[sample_name])\n",
    "    else:\n",
    "        max_length = max(len(np.concatenate(list(percentiles_dict.values()))) for percentiles_dict in percentiles_data.values())\n",
    "        for sample_name, percentiles_dict in percentiles_data.items():\n",
    "            vectors = list(percentiles_dict.values())\n",
    "            if vector_indices is not None:\n",
    "                selected_vectors = [vectors[i] for i in vector_indices if i < len(vectors)]\n",
    "                flattened_percentiles = np.concatenate(selected_vectors)\n",
    "            else:\n",
    "                flattened_percentiles = np.concatenate(vectors)\n",
    "            padded_percentiles = np.pad(flattened_percentiles, (0, max_length - len(flattened_percentiles)), 'constant')\n",
    "            data.append(padded_percentiles)\n",
    "            labels.append(labels_dict[sample_name])\n",
    "\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2)\n",
    "\n",
    "    scaler = sklearn.preprocessing.StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "def train_and_evaluate_knn(X_train, X_test, y_train, y_test, neighbors=5):\n",
    "    knn = KNeighborsClassifier(n_neighbors=neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(\"KNN Results\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    return knn, {'model': 'KNN', 'accuracy': accuracy, 'classification_report': class_report}\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def train_and_evaluate_logistic_regression(X_train, X_test, y_train, y_test):\n",
    "    logistic_regression = LogisticRegression()\n",
    "    logistic_regression.fit(X_train, y_train)\n",
    "    y_pred = logistic_regression.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(\"Logistic Regression Results\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    return logistic_regression, {'model': 'Logistic Regression', 'accuracy': accuracy, 'classification_report': class_report}\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def train_and_evaluate_svm(X_train, X_test, y_train, y_test):\n",
    "    svm = SVC()\n",
    "    svm.fit(X_train, y_train)\n",
    "    y_pred = svm.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(\"SVM Results\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    return svm, {'model': 'SVM', 'accuracy': accuracy, 'classification_report': class_report}\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def train_and_evaluate_decision_tree(X_train, X_test, y_train, y_test):\n",
    "    decision_tree = DecisionTreeClassifier()\n",
    "    decision_tree.fit(X_train, y_train)\n",
    "    y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(\"Decision Tree Results\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    return decision_tree, {'model': 'Decision Tree', 'accuracy': accuracy, 'classification_report': class_report}\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_and_evaluate_random_forest(X_train, X_test, y_train, y_test):\n",
    "    random_forest = RandomForestClassifier()\n",
    "    random_forest.fit(X_train, y_train)\n",
    "    y_pred = random_forest.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(\"Random Forest Results\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    return random_forest, {'model': 'Random Forest', 'accuracy': accuracy, 'classification_report': class_report}\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def train_and_evaluate_mlp(X_train, X_test, y_train, y_test):\n",
    "    neural_network = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300)\n",
    "    neural_network.fit(X_train, y_train)\n",
    "    y_pred = neural_network.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(\"MLP Results\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    return neural_network, {'model': 'MLP', 'accuracy': accuracy, 'classification_report': class_report}\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "def train_and_evaluate_xgboost(X_train, X_test, y_train, y_test):\n",
    "    model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(\"XGBoost Results:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    return model, {'model': 'XGBoost', 'accuracy': accuracy, 'classification_report': class_report}\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "def train_and_evaluate_nn(X_train, X_test, y_train, y_test):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        keras.layers.Dense(16, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=0)\n",
    "    \n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(\"Neural Network Results:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    return model, {'model': 'Neural Network', 'accuracy': accuracy, 'classification_report': class_report}\n",
    "\n",
    "def run_evaluation(X_train, X_test, y_train, y_test, k_value, results, models, save_results=True):\n",
    "    model_functions = [\n",
    "        ('KNN', train_and_evaluate_knn),\n",
    "        ('Logistic Regression', train_and_evaluate_logistic_regression),\n",
    "        ('SVM', train_and_evaluate_svm),\n",
    "        ('Decision Tree', train_and_evaluate_decision_tree),\n",
    "        ('Random Forest', train_and_evaluate_random_forest),\n",
    "        ('MLP', train_and_evaluate_mlp),\n",
    "        ('XGBoost', train_and_evaluate_xgboost), \n",
    "        ('Neural Network', train_and_evaluate_nn)\n",
    "    ]\n",
    "\n",
    "    for model_name, train_func in model_functions:\n",
    "        model, result = train_func(X_train, X_test, y_train, y_test)\n",
    "        if save_results:\n",
    "            results.append({'k_value': k_value, **result})\n",
    "            models.append({'k_value': k_value, 'model_name': model_name, 'model': model})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the model (after loading and proccesing the json file).\n",
    "The example below uses all the k value vectors, hence the k_value='all_k'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = prepare_data(all_results, labels_dict)\n",
    "\n",
    "run_evaluation(X_train, X_test, y_train, y_test, k_value=\"all_k\", results=results, models=models)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
