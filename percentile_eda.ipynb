{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "json file names and their threshold list:\n",
    "\n",
    "    results 1:[25, 50, 75, 90, 95, 99]\n",
    "\n",
    "    results 2: [10, 25, 40, 50, 60, 75, 90, 95]\n",
    "    \n",
    "    results 3: [5, 15, 25, 35, 50, 70, 80, 90, 95]\n",
    "\n",
    "cos = cosine simmilarity distance\n",
    "l2 = L2/Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('disk I/O error')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "SAVE = False\n",
    "OUTPUT_FILE = \"/home/users/orrbavly/GNN_project/percentiles/outputs/cos_3_all_results.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_JSON = \"/home/users/orrbavly/GNN_project/embeddings/percentiles_results_cos_3_all.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        all_results = json.load(f)\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = load_results(INPUT_JSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## k_values = [5, 10, 15, 20, int(np.sqrt(N)), int((np.sqrt(N))/2), log_k]\n",
    "def prepare_data(percentiles_data, labels_dict, vector_indices=None, average_vectors=False):\n",
    "    #  Vector indices: choose the vectors for flattened_percentiles \n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    if average_vectors:\n",
    "        # Use the average vector for each sample\n",
    "        for sample_name, percentiles_dict in percentiles_data.items():\n",
    "            vectors = np.array(list(percentiles_dict.values()))\n",
    "            avg_vector = np.mean(vectors, axis=0)\n",
    "            data.append(avg_vector)\n",
    "            labels.append(labels_dict[sample_name])\n",
    "    else:\n",
    "        # Determine the maximum length of the percentile vectors\n",
    "        max_length = max(len(np.concatenate(list(percentiles_dict.values()))) for percentiles_dict in percentiles_data.values())\n",
    "\n",
    "        for sample_name, percentiles_dict in percentiles_data.items():\n",
    "            vectors = list(percentiles_dict.values())  # Get list of vectors ordered by their insertion\n",
    "            if vector_indices is not None:\n",
    "                # Select specific vectors based on provided indices\n",
    "                selected_vectors = [vectors[i] for i in vector_indices if i < len(vectors)]\n",
    "                flattened_percentiles = np.concatenate(selected_vectors)\n",
    "            else:\n",
    "                # Flatten all vectors into a single feature vector\n",
    "                flattened_percentiles = np.concatenate(vectors)\n",
    "            \n",
    "            # Pad with zeros to match the maximum length\n",
    "            padded_percentiles = np.pad(flattened_percentiles, (0, max_length - len(flattened_percentiles)), 'constant')\n",
    "            data.append(padded_percentiles)\n",
    "            labels.append(labels_dict[sample_name])\n",
    "\n",
    "    # for sample_name, percentiles_dict in percentiles_data.items():\n",
    "    #     # Flatten the percentiles_dict into a single feature vector\n",
    "    #     flattened_percentiles = np.concatenate(list(percentiles_dict.values()))\n",
    "    #     data.append(flattened_percentiles)\n",
    "    #     labels.append(labels_dict[sample_name])\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2) # add random_state=42 for reproducibility\n",
    "\n",
    "    # Standardize the data\n",
    "    scaler = sklearn.preprocessing.StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_samples(data, criteria):\n",
    "    # filter samples from loaded all_result dict based on criteria (string)\n",
    "    filtered_data = {key: value for key, value in data.items() if criteria not in key.lower()}\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run this cell if you want to exclude sample groupes from df.\n",
    "# case is case sensetive\n",
    "# all_results = filter_samples(all_results, criteria=\"nh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {}\n",
    "for sample_name, percentile_dict in all_results.items():\n",
    "    if sample_name.endswith(\"_H\"):\n",
    "        labels_dict[sample_name] = 0\n",
    "    elif sample_name.endswith(\"_OC\"):\n",
    "        labels_dict[sample_name] = 1\n",
    "    else:\n",
    "        raise Exception(\"Error - invalid sample type\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def train_and_evaluate_knn(X_train, X_test, y_train, y_test, neighbors=5):\n",
    "    # Initialize the k-NN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=neighbors)  # You can tune the number of neighbors\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    # Evaluate the classifier\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(\"KNN Results\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    return knn, {'model': 'KNN', 'accuracy': accuracy, 'classification_report': class_report}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def train_and_evaluate_logistic_regression(X_train, X_test, y_train, y_test):\n",
    "    # Initialize the Logistic Regression classifier\n",
    "    logistic_regression = LogisticRegression()\n",
    "    logistic_regression.fit(X_train, y_train)\n",
    "    y_pred = logistic_regression.predict(X_test)\n",
    "\n",
    "    # Evaluate the classifier\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(\"Logistic Regression Results\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    return logistic_regression, {'model': 'Logistic Regression', 'accuracy': accuracy, 'classification_report': class_report}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def train_and_evaluate_svm(X_train, X_test, y_train, y_test):\n",
    "    # Initialize the SVM classifier\n",
    "    svm = SVC()\n",
    "    svm.fit(X_train, y_train)\n",
    "    y_pred = svm.predict(X_test)\n",
    "\n",
    "    # Evaluate the classifier\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(\"SVM Results\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    return svm, {'model': 'SVM', 'accuracy': accuracy, 'classification_report': class_report}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decition Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def train_and_evaluate_decision_tree(X_train, X_test, y_train, y_test):\n",
    "    # Initialize the Decision Tree classifier\n",
    "    decision_tree = DecisionTreeClassifier()\n",
    "    decision_tree.fit(X_train, y_train)\n",
    "    y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "    # Evaluate the classifier\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(\"Decision Tree Results\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    return decision_tree,  {'model': 'Decision Tree', 'accuracy': accuracy, 'classification_report': class_report}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_and_evaluate_random_forest(X_train, X_test, y_train, y_test):\n",
    "    # Initialize the Random Forest classifier\n",
    "    random_forest = RandomForestClassifier()\n",
    "    random_forest.fit(X_train, y_train)\n",
    "    y_pred = random_forest.predict(X_test)\n",
    "\n",
    "    # Evaluate the classifier\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(\"Random Forest Results\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    return random_forest, {'model': 'Random Forest', 'accuracy': accuracy, 'classification_report': class_report}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def train_and_evaluate_mlp(X_train, X_test, y_train, y_test):\n",
    "    # Initialize the Neural Network classifier\n",
    "    neural_network = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300)\n",
    "    neural_network.fit(X_train, y_train)\n",
    "    y_pred = neural_network.predict(X_test)\n",
    "\n",
    "    # Evaluate the classifier\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(\"MLP Results\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    return neural_network, {'model': 'MLP', 'accuracy': accuracy, 'classification_report': class_report}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "def train_and_evaluate_xgboost(X_train, X_test, y_train, y_test):\n",
    "    # Train the XGBoost model\n",
    "    model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    model.fit(X_train, y_train)\n",
    "    # Predict using the trained model\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the classifier\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(\"XGBoost Results:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    return model, {'model': 'XGBoost', 'accuracy': accuracy, 'classification_report': class_report}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network (Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "def train_and_evaluate_nn(X_train, X_test, y_train, y_test):\n",
    "    model = keras.Sequential([\n",
    "    keras.layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=0)\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "    # Evaluate the classifier\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(\"Neural Network Results:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    return model, {'model': 'Neural Network', 'accuracy': accuracy, 'classification_report': class_report}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various K values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results holds all the different k values (and their models) results.\n",
    "results = []\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation(X_train, X_test, y_train, y_test, k_value, results, models, save_results = True):\n",
    "    model_functions = [\n",
    "        ('KNN', train_and_evaluate_knn),\n",
    "        ('Logistic Regression', train_and_evaluate_logistic_regression),\n",
    "        ('SVM', train_and_evaluate_svm),\n",
    "        ('Decision Tree', train_and_evaluate_decision_tree),\n",
    "        ('Random Forest', train_and_evaluate_random_forest),\n",
    "        ('MLP', train_and_evaluate_mlp),\n",
    "        # ('XGBoost', train_and_evaluate_xgboost), \n",
    "        ('Neural Network', train_and_evaluate_nn)\n",
    "    ]\n",
    "\n",
    "    for model_name, train_func in model_functions:\n",
    "        model, result = train_func(X_train, X_test, y_train, y_test)\n",
    "        if save_results:\n",
    "            results.append({'k_value': k_value, **result})\n",
    "            models.append({'k_value': k_value, 'model_name': model_name, 'model': model})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = prepare_data(all_results, labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1\n",
      " 0 1 0 0 0 1 1 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0\n",
      " 1 0 1 0 1 0 1 1 0 0 0 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 0 0 1 0 0 1 0 1 0 0 1] 111\n",
      "[0 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0] 28\n"
     ]
    }
   ],
   "source": [
    "print(y_train, len(y_train))\n",
    "print(y_test, len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Results\n",
      "Accuracy: 0.6428571428571429\n",
      "Confusion Matrix:\n",
      "[[11  2]\n",
      " [ 8  7]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.85      0.69        13\n",
      "           1       0.78      0.47      0.58        15\n",
      "\n",
      "    accuracy                           0.64        28\n",
      "   macro avg       0.68      0.66      0.64        28\n",
      "weighted avg       0.69      0.64      0.63        28\n",
      "\n",
      "Logistic Regression Results\n",
      "Accuracy: 0.7857142857142857\n",
      "Confusion Matrix:\n",
      "[[12  1]\n",
      " [ 5 10]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.92      0.80        13\n",
      "           1       0.91      0.67      0.77        15\n",
      "\n",
      "    accuracy                           0.79        28\n",
      "   macro avg       0.81      0.79      0.78        28\n",
      "weighted avg       0.81      0.79      0.78        28\n",
      "\n",
      "SVM Results\n",
      "Accuracy: 0.8214285714285714\n",
      "Confusion Matrix:\n",
      "[[12  1]\n",
      " [ 4 11]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.83        13\n",
      "           1       0.92      0.73      0.81        15\n",
      "\n",
      "    accuracy                           0.82        28\n",
      "   macro avg       0.83      0.83      0.82        28\n",
      "weighted avg       0.84      0.82      0.82        28\n",
      "\n",
      "Decision Tree Results\n",
      "Accuracy: 0.7142857142857143\n",
      "Confusion Matrix:\n",
      "[[11  2]\n",
      " [ 6  9]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.85      0.73        13\n",
      "           1       0.82      0.60      0.69        15\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.73      0.72      0.71        28\n",
      "weighted avg       0.74      0.71      0.71        28\n",
      "\n",
      "Random Forest Results\n",
      "Accuracy: 0.7142857142857143\n",
      "Confusion Matrix:\n",
      "[[ 9  4]\n",
      " [ 4 11]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69        13\n",
      "           1       0.73      0.73      0.73        15\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.71      0.71      0.71        28\n",
      "weighted avg       0.71      0.71      0.71        28\n",
      "\n",
      "MLP Results\n",
      "Accuracy: 0.75\n",
      "Confusion Matrix:\n",
      "[[ 8  5]\n",
      " [ 2 13]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.62      0.70        13\n",
      "           1       0.72      0.87      0.79        15\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.76      0.74      0.74        28\n",
      "weighted avg       0.76      0.75      0.75        28\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-07-28 15:06:45.765488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79078 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:65:00.0, compute capability: 8.0\n",
      "2024-07-28 15:06:45.767792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 77385 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:ca:00.0, compute capability: 8.0\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722168408.320048 3973833 service.cc:145] XLA service 0x7fb050017e30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722168408.320214 3973833 service.cc:153]   StreamExecutor device (0): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "I0000 00:00:1722168408.320228 3973833 service.cc:153]   StreamExecutor device (1): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2024-07-28 15:06:48.981119: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-28 15:06:50.268159: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "I0000 00:00:1722168414.820261 3973833 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
      "Neural Network Results:\n",
      "Accuracy: 0.75\n",
      "Confusion Matrix:\n",
      "[[11  2]\n",
      " [ 5 10]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76        13\n",
      "           1       0.83      0.67      0.74        15\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.76      0.76      0.75        28\n",
      "weighted avg       0.77      0.75      0.75        28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_evaluation(X_train, X_test, y_train, y_test, k_value=\"all_k\", results=results, models=models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best score is Calculated on the validation folds during cross-validation and used to select the best hyperparameters, while\n",
    "Test accuracy is Calculated on the separate test set after the model is finalized and Provides an unbiased estimate of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'svm__C': 1, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n",
      "Best Score: 0.7391304347826086\n",
      "Test Accuracy: 0.7857142857142857\n",
      "[[13  0]\n",
      " [ 6  9]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a pipeline with scaling and SVM\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Feature scaling\n",
    "    ('svm', SVC())  # SVM classifier\n",
    "])\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'svm__C': [0.1, 1, 10, 100],\n",
    "    'svm__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'svm__gamma': [0.001, 0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the pipeline and parameter grid\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Predict using the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'rf__bootstrap': True, 'rf__max_depth': 20, 'rf__max_features': 'log2', 'rf__min_samples_leaf': 4, 'rf__min_samples_split': 10, 'rf__n_estimators': 50}\n",
      "Best Score: 0.7478260869565216\n",
      "Test Accuracy: 0.75\n",
      "[[ 9  4]\n",
      " [ 3 12]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a pipeline with scaling and Random Forest\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Feature scaling\n",
    "    ('rf', RandomForestClassifier())  # Random Forest classifier\n",
    "])\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'rf__n_estimators': [50, 100, 200],\n",
    "    'rf__max_depth': [None, 10, 20, 30],\n",
    "    'rf__min_samples_split': [2, 5, 10],\n",
    "    'rf__min_samples_leaf': [1, 2, 4],\n",
    "    'rf__max_features': ['sqrt', 'log2'],\n",
    "    'rf__bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the pipeline and parameter grid\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Predict using the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/dsi/orrbavly/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_re